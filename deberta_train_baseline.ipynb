{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1Hl2fpP6bM_5-Bpbhf-JvskGbEvo5IJf7","authorship_tag":"ABX9TyPaaN3MX3AjI66PTEaNzuYZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"IkTs1Us-9fTu","executionInfo":{"status":"ok","timestamp":1668585935792,"user_tz":-180,"elapsed":14610,"user":{"displayName":"Nurlan Rakhimzhanov","userId":"17222955390689933874"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d4f1c85f-95b8-48f7-ad78-208f7691d776"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.24.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.97)\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import time\n","from scipy import stats\n","from tqdm import tqdm\n","\n","import torch\n","from torch import nn\n","from torch.utils.data import Dataset, DataLoader\n","\n","!pip install transformers\n","!pip install sentencepiece\n","import tokenizers\n","import transformers\n","from transformers import AutoTokenizer, AutoModel, AutoConfig, AutoModelForSequenceClassification"]},{"cell_type":"code","source":["model_name = 'microsoft/deberta-v3-small'\n","# model_name = 'microsoft/deberta-v3-base'\n","# model_name = 'bert-base-uncased'\n","tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ArQzUAhISFGM","executionInfo":{"status":"ok","timestamp":1668585937477,"user_tz":-180,"elapsed":1687,"user":{"displayName":"Nurlan Rakhimzhanov","userId":"17222955390689933874"}},"outputId":"d753df9d-2218-462b-ed04-1e57920d2460"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","/usr/local/lib/python3.7/dist-packages/transformers/convert_slow_tokenizer.py:447: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  \"The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option\"\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"code","source":["df_train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/hse_mldm/train.csv')\n","df_test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/hse_mldm/test.csv')"],"metadata":{"id":"2YIOxURwqGno"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"6oblN-JvqYvB","executionInfo":{"status":"ok","timestamp":1668585937914,"user_tz":-180,"elapsed":439,"user":{"displayName":"Nurlan Rakhimzhanov","userId":"17222955390689933874"}},"outputId":"50e98994-ecef-4e0a-cefc-5b6d4b7c8fc7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                     id        anchor                  target context  score\n","0      37d61fd2272659b1     abatement  abatement of pollution     A47   0.50\n","1      7b9652b17b68b7a4     abatement          act of abating     A47   0.75\n","2      36d72442aefd8232     abatement         active catalyst     A47   0.25\n","3      5296b0c19e1ce60e     abatement     eliminating process     A47   0.50\n","4      54c1e3b9184cb5b6     abatement           forest region     A47   0.00\n","...                 ...           ...                     ...     ...    ...\n","36468  8e1386cbefd7f245  wood article          wooden article     B44   1.00\n","36469  42d9e032d1cd3242  wood article              wooden box     B44   0.50\n","36470  208654ccb9e14fa3  wood article           wooden handle     B44   0.50\n","36471  756ec035e694722b  wood article         wooden material     B44   0.75\n","36472  8d135da0b55b8c88  wood article        wooden substrate     B44   0.50\n","\n","[36473 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-a7cc0d4c-1764-4ea4-b90a-3b118491733a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>anchor</th>\n","      <th>target</th>\n","      <th>context</th>\n","      <th>score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>37d61fd2272659b1</td>\n","      <td>abatement</td>\n","      <td>abatement of pollution</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7b9652b17b68b7a4</td>\n","      <td>abatement</td>\n","      <td>act of abating</td>\n","      <td>A47</td>\n","      <td>0.75</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>36d72442aefd8232</td>\n","      <td>abatement</td>\n","      <td>active catalyst</td>\n","      <td>A47</td>\n","      <td>0.25</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5296b0c19e1ce60e</td>\n","      <td>abatement</td>\n","      <td>eliminating process</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>54c1e3b9184cb5b6</td>\n","      <td>abatement</td>\n","      <td>forest region</td>\n","      <td>A47</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>36468</th>\n","      <td>8e1386cbefd7f245</td>\n","      <td>wood article</td>\n","      <td>wooden article</td>\n","      <td>B44</td>\n","      <td>1.00</td>\n","    </tr>\n","    <tr>\n","      <th>36469</th>\n","      <td>42d9e032d1cd3242</td>\n","      <td>wood article</td>\n","      <td>wooden box</td>\n","      <td>B44</td>\n","      <td>0.50</td>\n","    </tr>\n","    <tr>\n","      <th>36470</th>\n","      <td>208654ccb9e14fa3</td>\n","      <td>wood article</td>\n","      <td>wooden handle</td>\n","      <td>B44</td>\n","      <td>0.50</td>\n","    </tr>\n","    <tr>\n","      <th>36471</th>\n","      <td>756ec035e694722b</td>\n","      <td>wood article</td>\n","      <td>wooden material</td>\n","      <td>B44</td>\n","      <td>0.75</td>\n","    </tr>\n","    <tr>\n","      <th>36472</th>\n","      <td>8d135da0b55b8c88</td>\n","      <td>wood article</td>\n","      <td>wooden substrate</td>\n","      <td>B44</td>\n","      <td>0.50</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>36473 rows × 5 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a7cc0d4c-1764-4ea4-b90a-3b118491733a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a7cc0d4c-1764-4ea4-b90a-3b118491733a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a7cc0d4c-1764-4ea4-b90a-3b118491733a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["context_mapping_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/hse_mldm/titles.csv')\n","context_mapping = {}\n","for code, context in zip(context_mapping_df['code'], context_mapping_df['title']):\n","    context_mapping[code] = context\n","\n","context_title_mapping = {\"A\" : \"Human Necessities\", \n","      \"B\" : \"Operations and Transport\",\n","      \"C\" : \"Chemistry and Metallurgy\",\n","      \"D\" : \"Textiles\",\n","      \"E\" : \"Fixed Constructions\",\n","      \"F\" : \"Mechanical Engineering\",\n","      \"G\" : \"Physics\",\n","      \"H\" : \"Electricity\",\n","      \"Y\" : \"Emerging Cross-Sectional Technologies\"}\n","\n","df_train['context_text'] = df_train['context'].apply(lambda x: context_mapping[x].lower())\n","df_train['context_title'] = df_train['context'].apply(lambda x: context_title_mapping[x[0]].lower())\n","\n","df_test['context_text'] = df_train['context'].apply(lambda x: context_mapping[x].lower())\n","df_test['context_title'] = df_train['context'].apply(lambda x: context_title_mapping[x[0]].lower())\n","\n","df_train['text'] = df_train['anchor'] + '[SEP]' + df_train['target'] + '[SEP]' + df_train['context_text']\n","df_test['text'] = df_test['anchor'] + '[SEP]' + df_test['target'] + '[SEP]' + df_test['context_text']\n","# df_train['text'] = df_train['anchor'] + ' ' + df_train['target'] + ' ' + df_train['context_text']\n","# df_test['text'] = df_test['anchor'] + ' ' + df_test['target'] + ' ' + df_test['context_text']"],"metadata":{"id":"kabhM1vypRYO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train"],"metadata":{"id":"nGzKpQVrXskg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["label_mapping = {0.0: 0, 0.25: 1, 0.5: 2, 0.75: 3, 1.0: 4}\n","df_train['label'] = df_train['score'].apply(lambda x: label_mapping[x])"],"metadata":{"id":"1d14VDlLNbUh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["context_text_lengths = []\n","for text in df_train['context_text']:\n","    context_text_lengths.append(len(tokenizer(text, add_special_tokens=False)['input_ids']))\n","max_context_text_length = max(context_text_lengths)\n","\n","anchor_lengths = []\n","for text in df_train['anchor']:\n","    anchor_lengths.append(len(tokenizer(text, add_special_tokens=False)['input_ids']))\n","max_anchor_length = max(anchor_lengths)\n","\n","target_lengths = []\n","for text in df_train['target']:\n","    target_lengths.append(len(tokenizer(text, add_special_tokens=False)['input_ids']))\n","max_target_length = max(target_lengths)\n","\n","max_len = max_context_text_length + max_anchor_length + max_target_length + 4\n","print(f'max_len={max_len}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cuMYLz6SRpNi","executionInfo":{"status":"ok","timestamp":1668585951472,"user_tz":-180,"elapsed":12769,"user":{"displayName":"Nurlan Rakhimzhanov","userId":"17222955390689933874"}},"outputId":"6397907b-fe10-4cfa-f0f6-a9e99f5dbb79"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["max_len=99\n"]}]},{"cell_type":"code","source":["X_train, X_valid = train_test_split(df_train, test_size=0.15, stratify=df_train['label'])"],"metadata":{"id":"MCqOfZm7OcfJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class TrainPatentDataset(Dataset):\n","    def __init__(self, df, tokenizer, max_len):\n","        # txt = df['text'].values.tolist()\n","        # self.texts = [tokenizer(str(i), padding='max_length', max_length = max_len, truncation=True, return_tensors=\"pt\") for i in txt]\n","        self.texts = df['text'].values.tolist()\n","        self.labels = df['label'].values.tolist()\n","        self.max_len = max_len\n","    def __len__(self):\n","        return len(self.texts)\n","    def __getitem__(self, idx):\n","        inputs = tokenizer(self.texts[idx], padding='max_length', max_length = self.max_len, truncation=True, return_tensors=\"pt\")\n","        for k, v in inputs.items():\n","            inputs[k] = v.squeeze(0)\n","        labels = torch.tensor(self.labels[idx], dtype=torch.long)\n","        return inputs, labels"],"metadata":{"id":"V2nEwZcDMTml"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class TestPatentDataset(Dataset):\n","    def __init__(self, df, tokenizer, max_len):\n","        self.texts = df['text'].values.tolist()\n","    def __len__(self):\n","        return len(self.texts)\n","    def __getitem__(self, idx):\n","        inputs = tokenizer(self.texts[idx], padding='max_length', max_length = self.max_len, truncation=True, return_tensors=\"pt\")\n","        for k, v in inputs.items():\n","            inputs[k] = v.squeeze(0)\n","        return inputs"],"metadata":{"id":"WaD2U1YsXIaL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","batch_size = 16\n","num_epochs = 5"],"metadata":{"id":"uC1U0DBBYmSc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = TrainPatentDataset(X_train, tokenizer, max_len)\n","valid_dataset = TrainPatentDataset(X_valid, tokenizer, max_len)\n","test_dataset = TestPatentDataset(df_test, tokenizer, max_len)\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n","valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"],"metadata":{"id":"dcsiaJouW5hU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CustomModel(nn.Module):\n","    def __init__(self, model_name):\n","        super().__init__()\n","        self.model = AutoModel.from_pretrained(model_name)\n","        self.fc_dropout = nn.Dropout()\n","        self.fc = nn.Linear(768, 5)\n","        self.attention = nn.Sequential(\n","            nn.Linear(768, 512),\n","            nn.Tanh(),\n","            nn.Linear(512, 1),\n","            nn.Softmax(dim=1)\n","        )\n","    def forward(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs[0]\n","        # feature = torch.mean(last_hidden_states, 1)\n","        weights = self.attention(last_hidden_states)\n","        feature = torch.sum(weights * last_hidden_states, dim=1)\n","        output = self.fc(self.fc_dropout(feature))\n","        return output"],"metadata":{"id":"tu3yw1FZbRW3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = CustomModel(model_name)\n","model = model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UiKBmrET521h","executionInfo":{"status":"ok","timestamp":1668586379243,"user_tz":-180,"elapsed":3679,"user":{"displayName":"Nurlan Rakhimzhanov","userId":"17222955390689933874"}},"outputId":"843cc7df-fdd3-4f91-f625-20a3ac3a2ac7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-v3-small were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LFXfpoNTUQBL","executionInfo":{"status":"ok","timestamp":1668586379243,"user_tz":-180,"elapsed":5,"user":{"displayName":"Nurlan Rakhimzhanov","userId":"17222955390689933874"}},"outputId":"a657fd11-3e89-4f18-c7eb-6b052f4f79ba"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["# criterion = nn.BCEWithLogitsLoss()\n","criterion = nn.CrossEntropyLoss()"],"metadata":{"id":"luMuVT1U_DqN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["params_to_update = model.parameters()\n","opt = torch.optim.SGD(params_to_update, lr=0.001, momentum=0.9)"],"metadata":{"id":"e-8129nM_FpV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["start = time.time()\n","train_loss_history = []\n","val_loss_history = []\n","val_pearson_history = []\n","valid_labels = X_valid['label']\n","\n","best_acc = 0.0\n","best_model_epoch = 0\n","for epoch in range(num_epochs):\n","    print(f'Epoch {epoch}/{num_epochs}')\n","\n","    train_loss = []\n","    model.train()\n","    for inputs, labels in tqdm(train_loader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        y_preds = model(inputs)\n","        # print(y_preds.shape, labels.shape)\n","        # print(labels)\n","        # print(y_preds)\n","\n","        opt.zero_grad()\n","        loss = criterion(y_preds, labels)\n","        train_loss.append(loss.item())\n","        # print(loss.item())\n","\n","        loss.backward()\n","        opt.step()\n","    \n","    train_loss = np.mean(train_loss)\n","    train_loss_history.append(train_loss)\n","    print(f'Train loss: {train_loss:.6f}')\n","\n","    model.eval()\n","    val_loss = []\n","    val_preds = []\n","    for inputs, labels in tqdm(valid_loader):\n","        with torch.no_grad():\n","            for k, v in inputs.items():\n","                inputs[k] = v.to(device)\n","            labels = labels.to(device)\n","            y_preds = model(inputs)\n","            loss = criterion(y_preds, labels)\n","            val_loss.append(loss.item())\n","            val_preds.append(y_preds.argmax(dim=-1).to('cpu').detach().numpy())\n","    val_loss = np.mean(val_loss)\n","    val_loss_history.append(val_loss)\n","    predictions = np.concatenate(val_preds)\n","    print(predictions)\n","    # predictions = np.concatenate(predictions)\n","    pear_cor = stats.pearsonr(valid_labels, predictions)[0]\n","    val_pearson_history.append(pear_cor)\n","    print(f'Valid loss: {val_loss:.6f}, Pearson: {pear_cor}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":744},"id":"L1Dfgr1M54su","executionInfo":{"status":"error","timestamp":1668587562784,"user_tz":-180,"elapsed":1182810,"user":{"displayName":"Nurlan Rakhimzhanov","userId":"17222955390689933874"}},"outputId":"e3c383c1-79c8-4b3d-f89e-5e320753d409"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0/5\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1938/1938 [06:09<00:00,  5.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 1.012258\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 342/342 [00:21<00:00, 16.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[0 1 2 ... 3 1 2]\n","Valid loss: 0.825436, Pearson: 0.7718519278222177\n","Epoch 1/5\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1938/1938 [06:11<00:00,  5.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.795099\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 342/342 [00:23<00:00, 14.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[0 1 2 ... 3 1 2]\n","Valid loss: 0.712673, Pearson: 0.8002987334179096\n","Epoch 2/5\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1938/1938 [06:11<00:00,  5.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.681554\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 342/342 [00:21<00:00, 16.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[0 1 2 ... 3 1 2]\n","Valid loss: 0.727994, Pearson: 0.8070091865989626\n","Epoch 3/5\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 24/1938 [00:04<06:22,  5.01it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-9fbf2d0317e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0my_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;31m# print(y_preds.shape, labels.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# print(labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-14-9cb7ecf038ef>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     12\u001b[0m         )\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mlast_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# feature = torch.mean(last_hidden_states, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m         )\n\u001b[1;32m   1106\u001b[0m         \u001b[0mencoded_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_hidden_states, output_attentions, query_states, relative_pos, return_dict)\u001b[0m\n\u001b[1;32m    546\u001b[0m                     \u001b[0mrelative_pos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelative_pos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m                     \u001b[0mrel_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrel_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m                 )\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, query_states, relative_pos, rel_embeddings, output_attentions)\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0mquery_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m             \u001b[0mrelative_pos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelative_pos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mrel_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrel_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m         )\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mquery_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mrelative_pos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelative_pos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0mrel_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrel_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m         )\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mrel_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrel_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m             rel_att = self.disentangled_attention_bias(\n\u001b[0;32m--> 749\u001b[0;31m                 \u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelative_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m             )\n\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mdisentangled_attention_bias\u001b[0;34m(self, query_layer, key_layer, relative_pos, rel_embeddings, scale_factor)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0matt_span\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_ebd_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m         \u001b[0mrelative_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelative_pos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m         \u001b[0mrel_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrel_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0matt_span\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["def save_network(network, epoch_label, device):\n","    save_path = f'patent_model_{epoch_label}.pth'\n","    torch.save(network.cpu().state_dict(), save_path)\n","    if device == 'cuda':\n","        network.to(device)"],"metadata":{"id":"eD0RHDGbWDVB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_network(model, 2, device)"],"metadata":{"id":"-KVKzuV4knaB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def save_network_drive(network, epoch_label, device):\n","    save_path = f'/content/drive/MyDrive/Colab Notebooks/hse_mldm/patent_model_{epoch_label}.pth'\n","    torch.save(network.cpu().state_dict(), save_path)\n","    if device == 'cuda':\n","        network.to(device)"],"metadata":{"id":"TYFQbqaSk7w2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_network_drive(model, 2, device)"],"metadata":{"id":"qWA093p1lI-b"},"execution_count":null,"outputs":[]}]}