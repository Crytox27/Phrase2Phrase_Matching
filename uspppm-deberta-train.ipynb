{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport time\nfrom scipy import stats\nfrom tqdm import tqdm\nfrom multiprocessing import cpu_count\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\n\nimport tokenizers\nimport transformers\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig, AutoModelForSequenceClassification\nfrom transformers import get_cosine_schedule_with_warmup","metadata":{"execution":{"iopub.status.busy":"2022-12-29T14:00:10.533171Z","iopub.execute_input":"2022-12-29T14:00:10.533729Z","iopub.status.idle":"2022-12-29T14:00:17.977509Z","shell.execute_reply.started":"2022-12-29T14:00:10.533598Z","shell.execute_reply":"2022-12-29T14:00:17.976414Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"model_name = 'microsoft/deberta-v3-base'","metadata":{"execution":{"iopub.status.busy":"2022-12-29T14:00:17.979548Z","iopub.execute_input":"2022-12-29T14:00:17.980384Z","iopub.status.idle":"2022-12-29T14:00:17.985629Z","shell.execute_reply.started":"2022-12-29T14:00:17.980347Z","shell.execute_reply":"2022-12-29T14:00:17.984492Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\ntokenizer.save_pretrained('./tokenizer/')\nconfig = AutoConfig.from_pretrained(model_name)\nconfig.save_pretrained('./config/')","metadata":{"execution":{"iopub.status.busy":"2022-12-29T14:00:17.987707Z","iopub.execute_input":"2022-12-29T14:00:17.988055Z","iopub.status.idle":"2022-12-29T14:00:24.475963Z","shell.execute_reply.started":"2022-12-29T14:00:17.988018Z","shell.execute_reply":"2022-12-29T14:00:24.474860Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9c1b2899d514a7fb47321963da42e3e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/579 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fe93a38f5e24f40ac1a796b9dffee09"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/2.35M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29f2a0050bfb4c7bbf34a57e74f57ad6"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n/opt/conda/lib/python3.7/site-packages/transformers/convert_slow_tokenizer.py:435: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  \"The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option\"\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/us-patent-phrase-to-phrase-matching/train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-12-29T14:00:24.479144Z","iopub.execute_input":"2022-12-29T14:00:24.479906Z","iopub.status.idle":"2022-12-29T14:00:24.580121Z","shell.execute_reply.started":"2022-12-29T14:00:24.479870Z","shell.execute_reply":"2022-12-29T14:00:24.579032Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"context_mapping_df = pd.read_csv('/kaggle/input/patentmatching-titles/titles.csv')\ncontext_mapping = {}\nfor code, context in zip(context_mapping_df['code'], context_mapping_df['title']):\n    context_mapping[code] = context\n\ncontext_title_mapping = {\"A\" : \"Human Necessities\", \n      \"B\" : \"Operations and Transport\",\n      \"C\" : \"Chemistry and Metallurgy\",\n      \"D\" : \"Textiles\",\n      \"E\" : \"Fixed Constructions\",\n      \"F\" : \"Mechanical Engineering\",\n      \"G\" : \"Physics\",\n      \"H\" : \"Electricity\",\n      \"Y\" : \"Emerging Cross-Sectional Technologies\"}\n\ndf_train['context_text'] = df_train['context'].apply(lambda x: context_mapping[x].lower())\ndf_train['context_title'] = df_train['context'].apply(lambda x: context_title_mapping[x[0]].lower())\n\ndf_train['text'] = df_train['anchor'] + '[SEP]' + df_train['target'] + '[SEP]' + df_train['context_text']","metadata":{"execution":{"iopub.status.busy":"2022-12-29T14:00:24.582413Z","iopub.execute_input":"2022-12-29T14:00:24.583446Z","iopub.status.idle":"2022-12-29T14:00:25.473370Z","shell.execute_reply.started":"2022-12-29T14:00:24.583381Z","shell.execute_reply":"2022-12-29T14:00:25.472408Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"label_mapping = {0.0: 0, 0.25: 1, 0.5: 2, 0.75: 3, 1.0: 4}\ndf_train['label'] = df_train['score'].apply(lambda x: label_mapping[x])","metadata":{"execution":{"iopub.status.busy":"2022-12-29T14:00:25.475042Z","iopub.execute_input":"2022-12-29T14:00:25.475382Z","iopub.status.idle":"2022-12-29T14:00:25.500429Z","shell.execute_reply.started":"2022-12-29T14:00:25.475347Z","shell.execute_reply":"2022-12-29T14:00:25.499520Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# df_train, _ = train_test_split(df_train, test_size=0.85, stratify=df_train['label'])\nX_train, X_valid = train_test_split(df_train, test_size=0.15, stratify=df_train['label'])","metadata":{"execution":{"iopub.status.busy":"2022-12-29T14:00:25.502367Z","iopub.execute_input":"2022-12-29T14:00:25.503922Z","iopub.status.idle":"2022-12-29T14:00:25.539482Z","shell.execute_reply.started":"2022-12-29T14:00:25.503891Z","shell.execute_reply":"2022-12-29T14:00:25.538543Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class TrainPatentDataset(Dataset):\n    def __init__(self, df, tokenizer, max_len):\n        self.texts = df['text'].values.tolist()\n        self.labels = df['score'].values.tolist()\n        self.max_len = max_len\n        self.tokenizer = tokenizer\n    def __len__(self):\n        return len(self.texts)\n    def __getitem__(self, idx):\n        inputs = self.tokenizer(self.texts[idx], padding='max_length', max_length = self.max_len, truncation=True, return_tensors=\"pt\")\n        for k, v in inputs.items():\n            inputs[k] = v.squeeze(0)\n        labels = torch.tensor(self.labels[idx])\n        return inputs, labels","metadata":{"execution":{"iopub.status.busy":"2022-12-29T14:00:25.542830Z","iopub.execute_input":"2022-12-29T14:00:25.543110Z","iopub.status.idle":"2022-12-29T14:00:25.553334Z","shell.execute_reply.started":"2022-12-29T14:00:25.543084Z","shell.execute_reply":"2022-12-29T14:00:25.552444Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class CustomModel(nn.Module):\n    def __init__(self, model_name):\n        super().__init__()\n        self.model = AutoModel.from_pretrained(model_name)\n        self.attention = nn.Sequential(\n            nn.Linear(768, 512),\n            nn.Tanh(),\n            nn.Linear(512, 1),\n            nn.Softmax(dim=1)\n        )\n        self.dropout1 = nn.Dropout()\n        self.dropout2 = nn.Dropout()\n        self.fc = nn.Linear(768, 1)\n        \n    def forward(self, inputs):\n        outputs = self.model(**inputs).last_hidden_state\n        outputs = self.dropout1(outputs)\n        weights = self.attention(outputs)\n        outputs = torch.sum(weights * outputs, dim=1)\n        outputs = self.fc(self.dropout2(outputs))\n        \n        return outputs","metadata":{"execution":{"iopub.status.busy":"2022-12-29T14:00:25.556928Z","iopub.execute_input":"2022-12-29T14:00:25.557292Z","iopub.status.idle":"2022-12-29T14:00:25.568013Z","shell.execute_reply.started":"2022-12-29T14:00:25.557226Z","shell.execute_reply":"2022-12-29T14:00:25.566857Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def save_model(model, epoch_label, model_save_name):\n    save_path = f'{model_save_name}_{epoch_label}.pth'\n    torch.save(model.state_dict(), save_path)","metadata":{"execution":{"iopub.status.busy":"2022-12-29T14:00:25.572735Z","iopub.execute_input":"2022-12-29T14:00:25.572986Z","iopub.status.idle":"2022-12-29T14:00:25.580177Z","shell.execute_reply.started":"2022-12-29T14:00:25.572963Z","shell.execute_reply":"2022-12-29T14:00:25.579243Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"max_len=128\nbatch_size = 32\nnum_workers=cpu_count()","metadata":{"execution":{"iopub.status.busy":"2022-12-29T14:00:25.581442Z","iopub.execute_input":"2022-12-29T14:00:25.582013Z","iopub.status.idle":"2022-12-29T14:00:25.587302Z","shell.execute_reply.started":"2022-12-29T14:00:25.581962Z","shell.execute_reply":"2022-12-29T14:00:25.586161Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_dataset = TrainPatentDataset(X_train, tokenizer, max_len)\nvalid_dataset = TrainPatentDataset(X_valid, tokenizer, max_len)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\nvalid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)","metadata":{"execution":{"iopub.status.busy":"2022-12-29T14:00:25.588960Z","iopub.execute_input":"2022-12-29T14:00:25.589442Z","iopub.status.idle":"2022-12-29T14:00:25.600794Z","shell.execute_reply.started":"2022-12-29T14:00:25.589409Z","shell.execute_reply":"2022-12-29T14:00:25.599630Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"model_save_name = 'uspppm_deberta'\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nnum_epochs=25\n\nlearning_rate=0.005\nnum_warmup_steps=1\nearly_stop_patience=5\n\nmodel = CustomModel(model_name)\nmodel = model.to(device)\n\ncriterion = nn.MSELoss()\n\nopt = torch.optim.AdamW(model.parameters(), lr=learning_rate)\nscheduler = get_cosine_schedule_with_warmup(opt, num_warmup_steps=num_warmup_steps, num_training_steps=num_epochs)","metadata":{"execution":{"iopub.status.busy":"2022-12-29T14:00:25.602294Z","iopub.execute_input":"2022-12-29T14:00:25.602856Z","iopub.status.idle":"2022-12-29T14:00:42.597325Z","shell.execute_reply.started":"2022-12-29T14:00:25.602820Z","shell.execute_reply":"2022-12-29T14:00:42.595740Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/354M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9bb317c15d1446c896e5f57ed43a2a8"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.weight', 'mask_predictions.dense.weight']\n- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"train_loss_history = []\nval_loss_history = []\nval_pearson_history = []\nvalid_labels = X_valid['label']\n\nbest_pearson = -1\nbest_epoch = 1\nfor epoch in range(1, num_epochs+1):\n    print(f'Epoch {epoch}')\n\n    train_loss = []\n    model.train()\n    for inputs, labels in tqdm(train_loader):\n        for k, v in inputs.items():\n            inputs[k] = v.to(device)\n        labels = labels.to(device)\n        y_preds = model(inputs).squeeze(-1)\n#         print(y_preds.shape, labels.shape)\n#         print(labels)\n#         print(y_preds)\n\n        opt.zero_grad()\n        loss = criterion(y_preds, labels)\n        train_loss.append(loss.item())\n#         print(loss.item())\n\n        loss.backward()\n        opt.step()\n    \n#     print(train_loss)\n    train_loss = np.mean(train_loss)\n    train_loss_history.append(train_loss)\n\n    model.eval()\n    val_loss = []\n    val_preds = []\n    for inputs, labels in tqdm(valid_loader):\n        with torch.no_grad():\n            for k, v in inputs.items():\n                inputs[k] = v.to(device)\n            labels = labels.to(device)\n            \n            y_preds = model(inputs).squeeze(-1)\n            loss = criterion(y_preds, labels)\n            val_loss.append(loss.item())\n#             val_preds.append(y_preds.sigmoid().cpu().detach().numpy())\n            val_preds.append(y_preds.cpu().detach().numpy())\n    val_loss = np.mean(val_loss)\n    val_loss_history.append(val_loss)\n    \n    predictions = np.concatenate(val_preds)\n    pear_cor = stats.pearsonr(valid_labels, predictions)[0]\n    val_pearson_history.append(pear_cor)\n    print(f'Train loss: {train_loss:.6f}')\n    print(f'Valid loss: {val_loss:.6f}, Pearson: {pear_cor:.6f}')\n    \n    scheduler.step()\n    \n    if pear_cor > best_pearson:\n        if epoch != 1:\n            os.remove(f'{model_save_name}_{best_epoch}.pth')\n        best_pearson = pear_cor\n        best_epoch = epoch\n        save_model(model, best_epoch, model_save_name)\n    elif epoch - best_epoch == early_stop_patience:\n        break","metadata":{"execution":{"iopub.status.busy":"2022-12-29T14:00:42.600362Z","iopub.execute_input":"2022-12-29T14:00:42.601014Z","iopub.status.idle":"2022-12-29T15:03:34.299198Z","shell.execute_reply.started":"2022-12-29T14:00:42.600972Z","shell.execute_reply":"2022-12-29T15:03:34.297766Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Epoch 1\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 969/969 [08:06<00:00,  1.99it/s]\n100%|██████████| 171/171 [00:26<00:00,  6.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.176892\nValid loss: 0.068938, Pearson: -0.041372\nEpoch 2\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 969/969 [08:04<00:00,  2.00it/s]\n100%|██████████| 171/171 [00:26<00:00,  6.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.070676\nValid loss: 0.068308, Pearson: -0.038714\nEpoch 3\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 969/969 [08:05<00:00,  2.00it/s]\n100%|██████████| 171/171 [00:27<00:00,  6.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.069205\nValid loss: 0.067117, Pearson: 0.038389\nEpoch 4\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 969/969 [08:05<00:00,  2.00it/s]\n100%|██████████| 171/171 [00:27<00:00,  6.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.068497\nValid loss: 0.066641, Pearson: 0.038064\nEpoch 5\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 969/969 [08:04<00:00,  2.00it/s]\n100%|██████████| 171/171 [00:26<00:00,  6.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.067772\nValid loss: 0.066928, Pearson: 0.039466\nEpoch 6\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 969/969 [08:04<00:00,  2.00it/s]\n100%|██████████| 171/171 [00:26<00:00,  6.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.067640\nValid loss: 0.066720, Pearson: 0.037792\nEpoch 7\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 969/969 [08:04<00:00,  2.00it/s]\n100%|██████████| 171/171 [00:26<00:00,  6.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.067922\nValid loss: 0.066674, Pearson: 0.037145\nEpoch 8\n","output_type":"stream"},{"name":"stderr","text":" 37%|███▋      | 357/969 [02:59<05:07,  1.99it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/3732105631.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#         print(loss.item())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}