{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport time\nfrom scipy import stats\nfrom tqdm import tqdm\nfrom multiprocessing import cpu_count\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\n\nimport tokenizers\nimport transformers\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig, AutoModelForSequenceClassification\nfrom transformers import get_cosine_schedule_with_warmup","metadata":{"execution":{"iopub.status.busy":"2022-12-29T02:46:17.475270Z","iopub.execute_input":"2022-12-29T02:46:17.475729Z","iopub.status.idle":"2022-12-29T02:46:24.640221Z","shell.execute_reply.started":"2022-12-29T02:46:17.475637Z","shell.execute_reply":"2022-12-29T02:46:24.639265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name1 = 'microsoft/deberta-v3-base'\nmodel_name2 = 'anferico/bert-for-patents'","metadata":{"execution":{"iopub.status.busy":"2022-12-29T02:46:24.642201Z","iopub.execute_input":"2022-12-29T02:46:24.643005Z","iopub.status.idle":"2022-12-29T02:46:24.648116Z","shell.execute_reply.started":"2022-12-29T02:46:24.642952Z","shell.execute_reply":"2022-12-29T02:46:24.647048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer1 = AutoTokenizer.from_pretrained(model_name1, use_fast=True)\ntokenizer1.save_pretrained('./tokenizer1/')\ntokenizer2 = AutoTokenizer.from_pretrained(model_name2, use_fast=True)\ntokenizer2.save_pretrained('./tokenizer2/')\n\nconfig1 = AutoConfig.from_pretrained(model_name1)\nconfig1.save_pretrained('./config1/')\nconfig2 = AutoConfig.from_pretrained(model_name2)\nconfig2.save_pretrained('./config2/')","metadata":{"execution":{"iopub.status.busy":"2022-12-29T02:46:24.649692Z","iopub.execute_input":"2022-12-29T02:46:24.650427Z","iopub.status.idle":"2022-12-29T02:46:35.628657Z","shell.execute_reply.started":"2022-12-29T02:46:24.650385Z","shell.execute_reply":"2022-12-29T02:46:35.627579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/us-patent-phrase-to-phrase-matching/train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-12-29T02:46:35.631458Z","iopub.execute_input":"2022-12-29T02:46:35.631822Z","iopub.status.idle":"2022-12-29T02:46:35.712394Z","shell.execute_reply.started":"2022-12-29T02:46:35.631787Z","shell.execute_reply":"2022-12-29T02:46:35.711495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"context_mapping_df = pd.read_csv('/kaggle/input/patentmatching-titles/titles.csv')\ncontext_mapping = {}\nfor code, context in zip(context_mapping_df['code'], context_mapping_df['title']):\n    context_mapping[code] = context\n\ncontext_title_mapping = {\"A\" : \"Human Necessities\", \n      \"B\" : \"Operations and Transport\",\n      \"C\" : \"Chemistry and Metallurgy\",\n      \"D\" : \"Textiles\",\n      \"E\" : \"Fixed Constructions\",\n      \"F\" : \"Mechanical Engineering\",\n      \"G\" : \"Physics\",\n      \"H\" : \"Electricity\",\n      \"Y\" : \"Emerging Cross-Sectional Technologies\"}\n\ndf_train['context_text'] = df_train['context'].apply(lambda x: context_mapping[x].lower())\ndf_train['context_title'] = df_train['context'].apply(lambda x: context_title_mapping[x[0]].lower())\n\ndf_train['text'] = df_train['anchor'] + '[SEP]' + df_train['target'] + '[SEP]' + df_train['context_text']","metadata":{"execution":{"iopub.status.busy":"2022-12-29T02:46:35.713694Z","iopub.execute_input":"2022-12-29T02:46:35.714068Z","iopub.status.idle":"2022-12-29T02:46:36.504207Z","shell.execute_reply.started":"2022-12-29T02:46:35.714031Z","shell.execute_reply":"2022-12-29T02:46:36.503253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_mapping = {0.0: 0, 0.25: 1, 0.5: 2, 0.75: 3, 1.0: 4}\ndf_train['label'] = df_train['score'].apply(lambda x: label_mapping[x])","metadata":{"execution":{"iopub.status.busy":"2022-12-29T02:46:36.505717Z","iopub.execute_input":"2022-12-29T02:46:36.506086Z","iopub.status.idle":"2022-12-29T02:46:36.527325Z","shell.execute_reply.started":"2022-12-29T02:46:36.506051Z","shell.execute_reply":"2022-12-29T02:46:36.525504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_train, _ = train_test_split(df_train, test_size=0.85, stratify=df_train['label'])\nX_train, X_valid = train_test_split(df_train, test_size=0.15, stratify=df_train['label'])","metadata":{"execution":{"iopub.status.busy":"2022-12-29T02:46:36.528851Z","iopub.execute_input":"2022-12-29T02:46:36.529198Z","iopub.status.idle":"2022-12-29T02:46:36.566313Z","shell.execute_reply.started":"2022-12-29T02:46:36.529165Z","shell.execute_reply":"2022-12-29T02:46:36.565467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TrainPatentDataset(Dataset):\n    def __init__(self, df, tokenizer1, tokenizer2, max_len):\n        self.texts = df['text'].values.tolist()\n        self.labels = df['score'].values.tolist()\n        self.max_len = max_len\n        self.tokenizer1 = tokenizer1\n        self.tokenizer2 = tokenizer2\n    def __len__(self):\n        return len(self.texts)\n    def __getitem__(self, idx):\n        inputs1 = self.tokenizer1(self.texts[idx], padding='max_length', max_length = self.max_len, truncation=True, return_tensors=\"pt\")\n        for k, v in inputs1.items():\n            inputs1[k] = v.squeeze(0)\n        inputs2 = self.tokenizer2(self.texts[idx], padding='max_length', max_length = self.max_len, truncation=True, return_tensors=\"pt\")\n        for k, v in inputs2.items():\n            inputs2[k] = v.squeeze(0)\n        labels = torch.tensor(self.labels[idx])\n        return inputs1, inputs2, labels","metadata":{"execution":{"iopub.status.busy":"2022-12-29T02:46:36.568751Z","iopub.execute_input":"2022-12-29T02:46:36.569697Z","iopub.status.idle":"2022-12-29T02:46:36.578313Z","shell.execute_reply.started":"2022-12-29T02:46:36.569661Z","shell.execute_reply":"2022-12-29T02:46:36.577132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomModel(nn.Module):\n    def __init__(self, model_name1, model_name2):\n        super().__init__()\n        self.model1 = AutoModel.from_pretrained(model_name1)\n        self.attention1 = nn.Sequential(\n            nn.Linear(768, 512),\n            nn.Tanh(),\n            nn.Linear(512, 1),\n            nn.Softmax(dim=1)\n        )\n        self.dropout11 = nn.Dropout()\n        \n        self.model2 = AutoModel.from_pretrained(model_name2)\n        self.attention2 = nn.Sequential(\n            nn.Linear(1024, 512),\n            nn.Tanh(),\n            nn.Linear(512, 1),\n            nn.Softmax(dim=1)\n        )\n        self.dropout12 = nn.Dropout()\n        \n        self.dropout2 = nn.Dropout()\n        self.fc = nn.Linear(768+1024, 1)\n        \n    def forward(self, inputs1, inputs2):\n        outputs1 = self.model1(**inputs1).last_hidden_state\n        outputs1 = self.dropout11(outputs1)\n        weights1 = self.attention1(outputs1)\n        outputs1 = torch.sum(weights1 * outputs1, dim=1)\n        \n        outputs2 = self.model2(**inputs2).last_hidden_state\n        outputs2 = self.dropout12(outputs2)\n        weights2 = self.attention2(outputs2)\n        outputs2 = torch.sum(weights2 * outputs2, dim=1)\n        \n        outputs = torch.cat((outputs1, outputs2), -1)\n        \n        outputs = self.fc(self.dropout2(outputs))\n        \n        return outputs","metadata":{"execution":{"iopub.status.busy":"2022-12-29T02:46:36.580013Z","iopub.execute_input":"2022-12-29T02:46:36.580476Z","iopub.status.idle":"2022-12-29T02:46:36.591691Z","shell.execute_reply.started":"2022-12-29T02:46:36.580442Z","shell.execute_reply":"2022-12-29T02:46:36.590598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_model(model, epoch_label, model_save_name):\n    save_path = f'{model_save_name}_{epoch_label}.pth'\n    torch.save(model.state_dict(), save_path)","metadata":{"execution":{"iopub.status.busy":"2022-12-29T02:46:36.595440Z","iopub.execute_input":"2022-12-29T02:46:36.595700Z","iopub.status.idle":"2022-12-29T02:46:36.603941Z","shell.execute_reply.started":"2022-12-29T02:46:36.595677Z","shell.execute_reply":"2022-12-29T02:46:36.603035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_len=128\nbatch_size = 8\nnum_workers=cpu_count()","metadata":{"execution":{"iopub.status.busy":"2022-12-29T02:46:36.605535Z","iopub.execute_input":"2022-12-29T02:46:36.605915Z","iopub.status.idle":"2022-12-29T02:46:36.612890Z","shell.execute_reply.started":"2022-12-29T02:46:36.605883Z","shell.execute_reply":"2022-12-29T02:46:36.611977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = TrainPatentDataset(X_train, tokenizer1, tokenizer2, max_len)\nvalid_dataset = TrainPatentDataset(X_valid, tokenizer1, tokenizer2, max_len)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\nvalid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)","metadata":{"execution":{"iopub.status.busy":"2022-12-29T02:46:36.614422Z","iopub.execute_input":"2022-12-29T02:46:36.614806Z","iopub.status.idle":"2022-12-29T02:46:36.624284Z","shell.execute_reply.started":"2022-12-29T02:46:36.614771Z","shell.execute_reply":"2022-12-29T02:46:36.623368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_save_name = 'uspppm_deberta'\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nnum_epochs=25\n\nlearning_rate=0.0005\nnum_warmup_steps=2\nearly_stop_patience=4\ngradient_accumulation = 4\n\nmodel = CustomModel(model_name1, model_name2)\nmodel = model.to(device)\n\ncriterion = nn.BCEWithLogitsLoss()\n\nopt = torch.optim.AdamW(model.parameters(), lr=learning_rate)\nscheduler = get_cosine_schedule_with_warmup(opt, num_warmup_steps=num_warmup_steps, num_training_steps=num_epochs)","metadata":{"execution":{"iopub.status.busy":"2022-12-29T02:46:36.625773Z","iopub.execute_input":"2022-12-29T02:46:36.626181Z","iopub.status.idle":"2022-12-29T02:47:35.039809Z","shell.execute_reply.started":"2022-12-29T02:46:36.626148Z","shell.execute_reply":"2022-12-29T02:47:35.038582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loss_history = []\nval_loss_history = []\nval_pearson_history = []\nvalid_labels = X_valid['label']\n\nbest_pearson = -1\nbest_epoch = 1\nstep_counter = 1\nfor epoch in range(1, num_epochs+1):\n    print(f'Epoch {epoch}')\n\n    train_loss = []\n    model.train()\n    for inputs1, inputs2, labels in tqdm(train_loader):\n        for k, v in inputs1.items():\n            inputs1[k] = v.to(device)\n        for k, v in inputs2.items():\n            inputs2[k] = v.to(device)\n        labels = labels.to(device)\n        y_preds = model(inputs1, inputs2).squeeze(-1)\n\n        loss = criterion(y_preds, labels)\n        train_loss.append(loss.item())\n\n        if gradient_accumulation > 1:\n            loss = loss / gradient_accumulation\n        loss.backward()\n        if step_counter % gradient_accumulation == 0:\n            opt.step()\n            opt.zero_grad()\n    \n#     print(train_loss)\n    train_loss = np.mean(train_loss)\n    train_loss_history.append(train_loss)\n\n    model.eval()\n    val_loss = []\n    val_preds = []\n    for inputs1, inputs2, labels in tqdm(valid_loader):\n        with torch.no_grad():\n            for k, v in inputs1.items():\n                inputs1[k] = v.to(device)\n            for k, v in inputs2.items():\n                inputs2[k] = v.to(device)\n            labels = labels.to(device)\n            \n            y_preds = model(inputs1, inputs2).squeeze(-1)\n            loss = criterion(y_preds, labels)\n            val_loss.append(loss.item())\n            val_preds.append(y_preds.sigmoid().cpu().detach().numpy())\n    val_loss = np.mean(val_loss)\n    val_loss_history.append(val_loss)\n    \n    predictions = np.concatenate(val_preds)\n    pear_cor = stats.pearsonr(valid_labels, predictions)[0]\n    val_pearson_history.append(pear_cor)\n    print(f'Train loss: {train_loss:.6f}')\n    print(f'Valid loss: {val_loss:.6f}, Pearson: {pear_cor:.6f}')\n    \n    scheduler.step()\n    \n    if pear_cor > best_pearson:\n        if epoch != 1:\n            os.remove(f'{model_save_name}_{best_epoch}.pth')\n        best_pearson = pear_cor\n        best_epoch = epoch\n        save_model(model, best_epoch, model_save_name)\n    elif epoch - best_epoch == early_stop_patience:\n        break","metadata":{"execution":{"iopub.status.busy":"2022-12-29T02:47:35.041625Z","iopub.execute_input":"2022-12-29T02:47:35.042072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}